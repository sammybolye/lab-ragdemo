{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca32908",
   "metadata": {},
   "source": [
    "# 05 - ETL Design Generator\n",
    "\n",
    "This notebook uses the RAG system to generate structured ETL designs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7d9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching RAG for: Customer 360 Integration from Salesforce to Snowflake\n",
      "Found 2 context chunks. Generating structured design with llama3...\n",
      "SUCCESS: Saved Machine-Actionable Design to ../results/design.json\n",
      "SUCCESS: Saved Human-Consumable Report to ../results/design_report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# ETL Design: Customer 360\n",
       "\n",
       "**Summary**: Migrates customer data from Salesforce Account object to Snowflake DIM_CUSTOMER table.\n",
       "\n",
       "## Systems\n",
       "- **Source**: Salesforce CRM (Account Table)\n",
       "- **Target**: Snowflake Data Warehouse (DIM_CUSTOMER)\n",
       "\n",
       "## Field Mappings\n",
       "| Source | Target | Logic | Business Rule |\n",
       "|---|---|---|---|\n",
       "| `AccountId` | `CUST_ID` | Direct Map | Primary Key, immutable. |\n",
       "| `Name` | `CUST_NAME` | UPPER(Name) | Standardize to uppercase for reporting |\n",
       "| `BillingState` | `STATE_CODE` | Lookup(StateMap) | Standardize state names to 2-letter codes |\n",
       "| `AnnualRevenue` | `REVENUE` | CAST(AnnualRevenue AS FLOAT) | Ensure numeric type |\n",
       "| `PersonEmail` | `PRIMARY_EMAIL` | LOWER(PersonEmail) | Strictly lowercased |\n",
       "| `Phone` | `CONTACT_PHONE` | Strip non-numeric characters (dashes, parentheses) | Raw digits only |\n",
       "\n",
       "## Validation Rules\n",
       "- ðŸ”´ **CUST_ID**: `Must be Unique and Not Null` (Severity: error)\n",
       "- ðŸ”´ **REVENUE**: `Must be >= 0` (Severity: error)\n",
       "- ðŸ”´ **STATE_CODE**: `Must be in the reference set of valid US State Codes` (Severity: error)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.etl_design_schema import EtlDesignDoc\n",
    "# UPDATED IMPORTS: Use new packages\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Config\n",
    "QDRANT_URL = \"http://qdrant:6333\"\n",
    "COLLECTION_NAME = \"etl_specs\"\n",
    "OLLAMA_URL = \"http://host.docker.internal:11434\"\n",
    "LLM_MODEL = \"llama3\" # Use a capable model for JSON extraction\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\"\n",
    "\n",
    "# 1. Setup Retrieval\n",
    "client = QdrantClient(url=QDRANT_URL)\n",
    "embeddings = OllamaEmbeddings(base_url=OLLAMA_URL, model=EMBEDDING_MODEL)\n",
    "# NOTE: We bypass langchain-qdrant vectorstore for retrieval to avoid client version conflicts (missing 'search' method)\n",
    "\n",
    "llm = ChatOllama(base_url=OLLAMA_URL, model=LLM_MODEL, temperature=0)\n",
    "\n",
    "# 2. Define Extraction Chain\n",
    "# Pydantic Parser ensures strict JSON structure matching our schema\n",
    "parser = PydanticOutputParser(pydantic_object=EtlDesignDoc)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert Data Architect. Your goal is to extract a structured ETL Design from the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "1. Analyize the context for source systems, target systems, and mapping rules.\n",
    "2. Identify specific field mappings. If logic is missing but implied (e.g., same name), note it as Direct.\n",
    "3. Identify any rigid validation rules described (e.g., \"Must not be null\", \"Must be unique\").\n",
    "4. Output STRICT JSON that matches the provided schema.\n",
    "\n",
    "IMPORTANT: \n",
    "- Output ONLY a valid JSON object.\n",
    "- Do NOT return the Schema definition itself.\n",
    "- Do NOT return markdown formatting like ```json.\n",
    "- Ensure all required fields (pipeline_name, summary, source, target) are filled.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "\n",
    "def retrieve_documents(query, k=5):\n",
    "    \"\"\"Manual retrieval using Qdrant Client to avoid langchain compatibility issues.\"\"\"\n",
    "    # 1. Embed Query\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    \n",
    "    # 2. Search using query_points (robust method)\n",
    "    try:\n",
    "        results = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=query_vector,\n",
    "            limit=k,\n",
    "            with_payload=True\n",
    "        ).points\n",
    "        \n",
    "        # 3. Extract text content from payload\n",
    "        docs = []\n",
    "        for point in results:\n",
    "            content = point.payload.get(\"page_content\", \"\")\n",
    "            docs.append(content)\n",
    "        return docs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Retrieval Error: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_design(query: str):\n",
    "    print(f\"Searching RAG for: {query}\")\n",
    "    \n",
    "    # Manual Retrieval Call\n",
    "    docs_content = retrieve_documents(query)\n",
    "    context = \"\\n\\n\".join(docs_content)\n",
    "    \n",
    "    if not context:\n",
    "        print(\"No relevant documents found in index. Did you run the ingestion notebook?\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(docs_content)} context chunks. Generating structured design with {LLM_MODEL}...\")\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    try:\n",
    "        design_obj = chain.invoke({\n",
    "            \"context\": context,\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        })\n",
    "        return design_obj\n",
    "    except Exception as e:\n",
    "        print(\"Error in generation/parsing:\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Modify this query to match the spec document you uploaded\n",
    "pipeline_query = \"Customer 360 Integration from Salesforce to Snowflake\"\n",
    "\n",
    "design = generate_design(pipeline_query)\n",
    "\n",
    "if design:\n",
    "    if not os.path.exists(\"../results\"):\n",
    "        os.makedirs(\"../results\")\n",
    "\n",
    "    # 3. Save Machine Actionable (JSON)\n",
    "    json_path = \"../results/design.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        f.write(design.model_dump_json(indent=2))\n",
    "    print(f\"SUCCESS: Saved Machine-Actionable Design to {json_path}\")\n",
    "\n",
    "    # 4. Generate Human Consumable (MD)\n",
    "    md_content = f\"# ETL Design: {design.pipeline_name}\\n\\n\"\n",
    "    md_content += f\"**Summary**: {design.summary}\\n\\n\"\n",
    "    md_content += f\"## Systems\\n- **Source**: {design.source.system_name} ({design.source.object_name})\\n\"\n",
    "    md_content += f\"- **Target**: {design.target.system_name} ({design.target.object_name})\\n\\n\"\n",
    "    md_content += \"## Field Mappings\\n| Source | Target | Logic | Business Rule |\\n|---|---|---|---|\\n\"\n",
    "    for m in design.field_mappings:\n",
    "        logic = m.transformation_logic or 'Direct'\n",
    "        rule = m.business_rule or '-'\n",
    "        md_content += f\"| `{m.source_field}` | `{m.target_field}` | {logic} | {rule} |\\n\"\n",
    "    \n",
    "    md_content += \"\\n## Validation Rules\\n\"\n",
    "    for r in design.data_quality_rules:\n",
    "        md_content += f\"- ðŸ”´ **{r.target_field}**: `{r.rule_type}` (Severity: {r.severity})\\n\"\n",
    "        \n",
    "    md_path = \"../results/design_report.md\"\n",
    "    with open(md_path, \"w\") as f:\n",
    "        f.write(md_content)\n",
    "    print(f\"SUCCESS: Saved Human-Consumable Report to {md_path}\")\n",
    "    \n",
    "    # Display for the notebook user\n",
    "    from IPython.display import Markdown\n",
    "    display(Markdown(md_content))\n",
    "else:\n",
    "    print(\"Failed to generate design.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1add5-1aec-42fa-af97-7ecd56533924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
